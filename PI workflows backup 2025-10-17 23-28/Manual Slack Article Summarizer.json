{
  "createdAt": "2025-09-02T14:15:51.644Z",
  "updatedAt": "2025-10-07T10:24:24.000Z",
  "id": "UkPfwOVWETGpaImb",
  "name": "Manual Slack Article Summarizer",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -3904,
        -384
      ],
      "id": "08a8a547-f00b-42e1-8587-46272f7de55d",
      "name": "When clicking ‘Execute workflow’"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are a summarization tool.\n\nSummarize the following text in {{$json[\"language\"]}}.\n- If \"he\" → write the title and bullets in Hebrew.\n- If \"en\" → write the title and bullets in English.\n\nNever translate — always summarize in the language provided by {{$json[\"language\"]}}.\n\nSummarize into exactly 5 detailed bullet points and a short title.\n\n⚠️ Important:\n- Output must be ONLY valid JSON (no extra text).\n- Always return 5 bullet points.\n- Each bullet should be 40-60 words (3-5 complete sentences).\n- Include specific details: names, dates, numbers, locations, organizations.\n- Provide context and explain why events matter.\n- Write complete sentences with proper grammar.\n- Do NOT include bullet characters (•) in your output.\n- If the text is unclear or empty, still return JSON with a generic title and 5 short placeholders.\n\nFormat:\n{\n  \"title\": \"Short descriptive title (same language)\",\n  \"bullets\": [\n    \"First detailed point with 3-5 complete sentences including names and facts.\",\n    \"Second detailed point with 3-5 complete sentences including context.\",\n    \"Third detailed point with 3-5 complete sentences including background.\",\n    \"Fourth detailed point with 3-5 complete sentences including reactions.\",\n    \"Fifth detailed point with 3-5 complete sentences including implications.\"\n  ]\n}\n\nText:\n{{ $json[\"chunk\"] }}",
        "needsFallback": true,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        -2656,
        -384
      ],
      "id": "431d2267-e0ee-4fdc-91bb-f93429a95f2e",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "google/gemma-3-12b",
          "mode": "list",
          "cachedResultName": "google/gemma-3-12b"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -2752,
        -80
      ],
      "id": "c08bd86e-4d56-4b39-b171-bd9cd7f11c7c",
      "name": "AI Model",
      "credentials": {
        "openAiApi": {
          "id": "tPLXnEcJzshXrwfS",
          "name": "Mac-AI"
        }
      }
    },
    {
      "parameters": {
        "url": "https://gizmodo.com/have-a-cow-man-theyre-making-a-second-simpsons-movie-2000665123",
        "options": {
          "response": {
            "response": {
              "responseFormat": "text"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3600,
        -384
      ],
      "id": "0369dc52-0b07-435c-8400-1862d344f2e0",
      "name": "HTTP Request1"
    },
    {
      "parameters": {
        "select": "channel",
        "channelId": {
          "__rl": true,
          "value": "C09BFKKCMQ8",
          "mode": "list",
          "cachedResultName": "n8n-sammarize"
        },
        "text": "={{$json[\"text\"]}}",
        "otherOptions": {}
      },
      "type": "n8n-nodes-base.slack",
      "typeVersion": 2.3,
      "position": [
        -1216,
        -384
      ],
      "id": "9dbf698b-dc50-4dc8-8459-457e7cbb2f63",
      "name": "Send a message1",
      "webhookId": "fb37895d-0d8c-46d3-bb18-44e99df4fbf3",
      "credentials": {
        "slackApi": {
          "id": "I5astSkOODZZU76Y",
          "name": "n8n Summery"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Log input for debugging\nconst inputData = $input.first().json;\nconsole.log(\"HTML Extract input fields:\", Object.keys(inputData));\n\nconst html = inputData.data || inputData.html || inputData.body || inputData.content || inputData.response || \"\";\nconsole.log(\"HTML length:\", html.length, \"Sample:\", html.slice(0, 500));\n\nif (!html) {\n  console.log(\"No HTML content found\");\n  return { error: \"No HTML content found\", availableFields: Object.keys(inputData) };\n}\n\nconst MAX_LENGTH = 200000;\nlet matches = null;\nlet text = \"\";\n\n// --- Step 1: Extract from <p> and <h1-h6> ---\ntry {\n  matches = html.match(/<(p|h[1-6])[^>]*>(.*?)<\\/(p|h[1-6])>/gis);\n  if (matches) {\n    text = matches\n      .map(m => m.replace(/<[^>]+>/g, \"\").trim())\n      .filter(t => t.length > 5)\n      .join(\"\\n\\n\");\n  }\n} catch (e) {\n  console.log(\"Regex error (p/h-tags):\", e.message);\n}\n\n// --- Step 2: Fallback to <div>/<span> with article-related classes ---\nif (text.length < 100) {\n  console.log(\"Fallback: checking <div>/<span> for article text\");\n  try {\n    matches = html.match(/<(div|span)[^>]*(article|content|body|text)[^>]*>(.*?)<\\/(div|span)>/gis);\n    if (matches) {\n      text = matches\n        .map(m => m.replace(/<[^>]+>/g, \"\").trim())\n        .filter(t => t.length > 5)\n        .join(\"\\n\\n\");\n    }\n  } catch (e) {\n    console.log(\"Regex error (div/span fallback):\", e.message);\n  }\n}\n\n// --- Step 3: Fallback to embedded JSON (with recursive search) ---\nfunction findArticleText(obj) {\n  if (!obj || typeof obj !== \"object\") return null;\n\n  if (obj.articleBody && typeof obj.articleBody === \"string\") return obj.articleBody;\n  if (obj.text && typeof obj.text === \"string\" && obj.text.length > 100) return obj.text;\n\n  if (Array.isArray(obj)) {\n    for (const el of obj) {\n      const result = findArticleText(el);\n      if (result) return result;\n    }\n  } else {\n    for (const key of Object.keys(obj)) {\n      const result = findArticleText(obj[key]);\n      if (result) return result;\n    }\n  }\n  return null;\n}\n\nif (text.length < 100) {\n  console.log(\"Fallback: checking for JSON article data\");\n  try {\n    const jsonBlocks = html.match(/<script[^>]+type=[\"']application\\/(ld\\+json|json)[\"'][^>]*>([\\s\\S]*?)<\\/script>/gi);\n    if (jsonBlocks) {\n      for (let block of jsonBlocks) {\n        try {\n          const clean = block.replace(/<script[^>]*>/i, \"\").replace(/<\\/script>/i, \"\").trim();\n          const parsed = JSON.parse(clean);\n          const result = findArticleText(parsed);\n          if (result) {\n            text = result;\n            break;\n          }\n        } catch (err) {\n          console.log(\"JSON parse error in block:\", err.message);\n        }\n      }\n    }\n  } catch (e) {\n    console.log(\"JSON parse fallback error:\", e.message);\n  }\n}\n\n// --- Step 4: Final error handling ---\nif (!text || text.length < 100) {\n  console.log(\"Article body not found (likely JS-rendered or blocked).\");\n  return { \n    error: \"Article body not found (likely JS-rendered or blocked)\", \n    availableFields: Object.keys(inputData),\n    originalLength: html.length,\n    rawSample: html.slice(0, 500)\n  };\n}\n\nconsole.log(\"Extracted text length:\", text.length, \"Sample:\", text.slice(0, 500));\n\nif (text.length > MAX_LENGTH) {\n  text = text.substring(0, MAX_LENGTH) + \"... [truncated]\";\n}\n\nreturn { \n  article: text, \n  originalLength: html.length, \n  extractedLength: text.length \n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3360,
        -384
      ],
      "id": "c8447a60-c3b0-4aac-afd0-3589fd265455",
      "name": "Extract Article Text1"
    },
    {
      "parameters": {
        "jsCode": "// Log input\nconsole.log(\"Validator input:\", JSON.stringify($json, null, 2));\n\nlet raw = $json.output || $json.text || $json.content || \"\";\nif (typeof raw !== \"string\") raw = JSON.stringify(raw);\n\n// Normalize\nlet s = raw\n  .replace(/-/g, \"-\")\n  .replace(/[\\r\\n]+/g, \" \")\n  .replace(/[\\u2018\\u2019]/g, \"'\")\n  .replace(/[\\u201C\\u201D]/g, '\"')\n  .trim();\n\n// Remove markdown\ns = s.replace(/```json\\s*/gi, \"\").replace(/```\\s*/g, \"\").trim();\n\nlet obj = null;\ntry {\n  obj = JSON.parse(s);\n  if (typeof obj === \"string\") obj = JSON.parse(obj);\n} catch (e) {\n  console.log(\"JSON parse failed:\", e.message);\n}\n\n// Try regex salvage if parse failed\nif (!obj || typeof obj !== \"object\") {\n  const titleMatch = s.match(/\"title\"\\s*:\\s*\"([^\"]+)\"/);\n  const bulletsMatch = s.match(/\"bullets\"\\s*:\\s*\\[([\\s\\S]*?)\\]/);\n\n  if (titleMatch && bulletsMatch) {\n    const title = titleMatch[1];\n    const bullets = [...bulletsMatch[1].matchAll(/\"([^\"]+)\"/g)].map(m => m[1]);\n\n    return [{\n      json: {\n        title,\n        bullets,\n        url: $json.url || null,\n        source: $json.source || \"Local\",\n        language: $json.language || \"en\"\n      }\n    }];\n  }\n\n  return [{\n    json: {\n      error: \"Failed to parse AI output into JSON\",\n      raw: s.slice(0, 500),\n      url: $json.url || null,\n      language: $json.language || \"en\"\n    }\n  }];\n}\n\n// Normal success path\nlet title = obj.title || \"Summary\";\nlet bullets = Array.isArray(obj.bullets) ? obj.bullets : [];\n\nif (bullets.length > 5) bullets = bullets.slice(0, 5);\nwhile (bullets.length < 5) {\n  bullets.push(\"No further details available.\");\n}\n\nreturn [{\n  json: {\n    title,\n    bullets,\n    url: $json.url || null,\n    source: $json.source || \"Local\",\n    language: $json.language || \"en\"\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1984,
        -384
      ],
      "id": "57443ef8-ab9d-49b0-9131-62bd9bfd2911",
      "name": "Validator1"
    },
    {
      "parameters": {
        "jsCode": "const { \n  title = \"Summary\", \n  bullets = [], \n  error = null, \n  raw = \"\", \n  url = \"\",\n  language = \"en\"\n} = $json || {};\n\n// --- Error case ---\nif (error) {\n  const errorMsg = language === \"he\" ? \"שגיאה בעיבוד המאמר\" : \"Error processing article\";\n  const sourceText = language === \"he\" ? \"מקור:\" : \"Source:\";\n  \n  return [{\n    json: {\n      text: `⚠️ ${errorMsg}\\n\\n${sourceText} ${url ? `<${url}|${url}>` : (language === \"he\" ? \"לא ידוע\" : \"Unknown\")}\\n\\n\\`\\`\\`\\n${raw?.slice(0, 500) || (language === \"he\" ? \"אין תוכן\" : \"No content\")}\\n\\`\\`\\``\n    }\n  }];\n}\n\n// Clean title\nlet cleanTitle = String(title)\n  .replace(/^[^{\"]*\"?title[\"']?\\s*[:=–-]\\s*/i, \"\")\n  .replace(/^[\"']|[\"']$/g, \"\")\n  .replace(/[.,\"]+$/, \"\")\n  .trim()\n  .replace(/automated with this n8n workflow/i, \"\")\n  .trim();\n\n// Clean bullets\nlet cleanBullets = (Array.isArray(bullets) ? bullets : [])\n  .map(b => String(b).trim())\n  .filter(b => b && !/^[\"']?title[\"']?\\s*[:=–-]/i.test(b))\n  .filter(b => !/automated with this n8n workflow/i.test(b))\n  .map(b => {\n    let cleaned = b.replace(/^[\"']|[\"']$/g, \"\").replace(/[.,\"]+$/, \"\").trim();\n    \n    // Strip ALL bullet characters\n    cleaned = cleaned.replace(/^[•\\s]+/g, \"\").trim();\n    \n    // Fix double periods\n    cleaned = cleaned.replace(/\\.{2,}/g, \".\");\n    \n    // CAPITALIZE FIRST LETTER\n    if (cleaned.length > 0) {\n      cleaned = cleaned.charAt(0).toUpperCase() + cleaned.slice(1);\n    }\n    \n    // Add period if needed\n    const needsPeriod = !/[.!?]$/.test(cleaned) && !/[׃׀]$/.test(cleaned);\n    return needsPeriod ? `${cleaned}.` : cleaned;\n  })\n  .filter(Boolean)\n  .slice(0, 5);\n\n// Guarantee 5 bullets\nconst defaultBullet = language === \"he\" ? \"לא נמצאו פרטים נוספים\" : \"No further details available\";\nwhile (cleanBullets.length < 5) {\n  cleanBullets.push(defaultBullet);\n}\n\n// Build Slack message\nconst RTL = \"\\u200F\";\nconst summaryText = language === \"he\" ? \"סיכום:\" : \"Summary:\";\n\nif (language === \"he\") {\n  const parts = [\n    `:brain: ${summaryText} ${url ? `<${url}|${RTL}${cleanTitle}${RTL}>` : RTL + cleanTitle + RTL}`,\n    \"\",\n    ...cleanBullets.map((b, i) => `${i + 1}. ${RTL}${b}${RTL}`),\n    \"\"\n  ];\n  return [{ json: { text: parts.join(\"\\n\") } }];\n} else {\n  const parts = [\n    `:brain: ${summaryText} ${url ? `<${url}|${cleanTitle}>` : cleanTitle}`,\n    \"\",\n    ...cleanBullets.map(b => `• ${b}`),\n    \"\"\n  ];\n  return [{ json: { text: parts.join(\"\\n\") } }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1616,
        -384
      ],
      "id": "213ebb2f-24cd-43f1-826a-c398408db597",
      "name": "Formatter1"
    },
    {
      "parameters": {
        "jsCode": "console.log(\"Chunker input article length:\", $json.article?.length || 0, \"Sample:\", $json.article?.slice(0, 500));\n\nconst CHUNK_SIZE = 2000;\nconst OVERLAP = 150;\nconst MAX_CHUNKS = 20;\n\nconst text = $json.article || \"\";\nconst url = $json.url || \"\";\nconst chunks = [];\n\nfor (let i = 0; i < text.length && chunks.length < MAX_CHUNKS; i += (CHUNK_SIZE - OVERLAP)) {\n  chunks.push({ json: { url, chunk: text.slice(i, i + CHUNK_SIZE), index: chunks.length + 1 } });\n}\n\nconsole.log(\"Generated chunks:\", chunks.length, \"Sample chunk:\", chunks[0]?.json.chunk.slice(0, 500));\nreturn chunks;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3184,
        -384
      ],
      "id": "86182bc0-e458-40a9-bb5d-6ab66dd6b296",
      "name": "Chunker1"
    },
    {
      "parameters": {
        "jsCode": "// LANGUAGE DETECTOR NODE\nconst text = $json.article || $json.chunk || \"\";\nif (!text) {\n  return [{\n    json: { \n      language: \"en\",\n      chunk: $json.chunk || \"\", \n      url: $json.url || \"\" \n    }\n  }];\n}\n\n// Count Hebrew characters\nconst hebrewMatches = text.match(/[\\u0590-\\u05FF]/g) || [];\nconst hebrewChars = hebrewMatches.length;\nconst totalChars = text.length;\nconst hebrewRatio = hebrewChars / totalChars;\n\n// Only treat as Hebrew if at least 20% of characters are Hebrew AND total length > 200\nconst language = (hebrewRatio > 0.2 && totalChars > 200) ? \"he\" : \"en\";\n\nconsole.log(`Language detected: ${language}, Hebrew chars: ${hebrewChars}, Ratio: ${hebrewRatio.toFixed(3)}, Total: ${totalChars}`);\n\nreturn [{\n  json: {\n    language,\n    chunk: $json.chunk || \"\",\n    url: $json.url || \"\"\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2944,
        -384
      ],
      "id": "600221ab-e11e-443d-81bc-8a6e31012bdf",
      "name": "Language Detector1"
    },
    {
      "parameters": {
        "jsCode": "console.log(\"AI Agent output:\", JSON.stringify($json, null, 2));\nreturn [$json];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2304,
        -384
      ],
      "id": "16386a57-5709-42cf-b26b-f01b39870ccc",
      "name": "Debug logger1"
    },
    {
      "parameters": {
        "model": "openai/gpt-5-nano",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        -2528,
        -80
      ],
      "id": "93766d73-9dee-4e9c-a37b-a7bb8378e031",
      "name": "OpenRouter Chat Model",
      "credentials": {
        "openRouterApi": {
          "id": "hGAnvpSAhWRbFktq",
          "name": "OpenRouter account"
        }
      }
    }
  ],
  "connections": {
    "When clicking ‘Execute workflow’": {
      "main": [
        [
          {
            "node": "HTTP Request1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent": {
      "main": [
        [
          {
            "node": "Debug logger1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Request1": {
      "main": [
        [
          {
            "node": "Extract Article Text1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Article Text1": {
      "main": [
        [
          {
            "node": "Chunker1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validator1": {
      "main": [
        [
          {
            "node": "Formatter1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Formatter1": {
      "main": [
        [
          {
            "node": "Send a message1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chunker1": {
      "main": [
        [
          {
            "node": "Language Detector1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Language Detector1": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Debug logger1": {
      "main": [
        [
          {
            "node": "Validator1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "pinData": {},
  "versionId": "ce3534fb-31b9-4746-8647-5424d14ede84",
  "triggerCount": 0,
  "shared": [
    {
      "createdAt": "2025-09-02T14:15:51.648Z",
      "updatedAt": "2025-09-02T14:15:51.648Z",
      "role": "workflow:owner",
      "workflowId": "UkPfwOVWETGpaImb",
      "projectId": "NptNxIUgBjUJaRfd"
    }
  ],
  "tags": []
}